{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5f53d5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shap\n",
    "from datetime import datetime\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "50860da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consider new reading as\n",
    "new_reading = {\n",
    "    \"Timestamp\": '8/3/2021  4:26:38 PM',\n",
    "    \"OxEnRa\": 4.5,  # Increased oxygen enrichment - will contribute to high SI\n",
    "    \"BlFuPeIn\": 25.0,  # Increased blast furnace pressure index\n",
    "    \"EnOxFl\": 15000.0,  # Higher enriched oxygen flow\n",
    "    \"CoBlFl\": 75.0,  # Higher coal blast flow\n",
    "    \"BlMo\": 160.0,  # Higher blast momentum\n",
    "    \"BlFuBoGaVo\": 8000.0,  # Higher blast furnace bottom gas volume\n",
    "    \"BlFuBoGaIn\": 85.0,  # Higher blast furnace bottom gas index\n",
    "    \"ThCoTe\": 2300.0,  # Higher theoretical combustion temperature\n",
    "    \"ToGaPr\": 250.0,  # Higher top gas pressure\n",
    "    \"EnOxPr\": 1.8,  # Higher enriched oxygen pressure\n",
    "    \"CoBlPr\": 0.6,  # Higher coal blast pressure\n",
    "    \"ToPrDr\": 220.0,  # Higher top pressure drop\n",
    "    \"HoBlPr\": 0.5,  # Higher hot blast pressure\n",
    "    \"AcBlVe\": 280.0,  # Higher actual blast velocity\n",
    "    \"CoBlTe\": 250.0,  # Higher coal blast temperature\n",
    "    \"HoBlTe\": 1100.0,  # Higher hot blast temperature\n",
    "    \"ToTe\": 230.0,  # Higher top temperature\n",
    "    \"BlHu\": 20.0,  # Higher blast humidity\n",
    "    \"CoInSeVa\": 50.0,  # Higher coke index and set value\n",
    "    \"FoSI\": 0.9,  # Higher forecast SI - critical high threshold\n",
    "    \"HoBl\": 1100.0,  # Higher hot blast\n",
    "    \"ToGasP\": 240.0,  # Higher top gas pressure\n",
    "    \"CoBF\": 75.0,  # Higher coke blast furnace\n",
    "    \"SI_lag1\": 0.88,  # High lagged SI value\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5be1d16c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ABC1\\AppData\\Local\\Temp\\ipykernel_8700\\406587172.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.fillna(pipeline['null_fill_values'], inplace=True)\n",
      "C:\\Users\\ABC1\\AppData\\Local\\Temp\\ipykernel_8700\\406587172.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[pipeline['feature_columns']] = pipeline['scaler'].transform(df[pipeline['feature_columns']])\n"
     ]
    }
   ],
   "source": [
    "#converting the new reading to a DataFrame\n",
    "new_reading_df = pd.DataFrame([new_reading])\n",
    "#loding the preprocessing pipeline\n",
    "with open('preprocessing_pipeline.pkl', 'rb') as f:\n",
    "    preprocessing_pipeline = pickle.load(f)\n",
    "# Apply preprocessing steps\n",
    "def preprocess_data(df, pipeline):\n",
    "    # Selecting feature columns\n",
    "    df = df[pipeline['feature_columns']]\n",
    "    # Fill null values\n",
    "    df.fillna(pipeline['null_fill_values'], inplace=True)\n",
    "    \n",
    "    # Scale features\n",
    "    df[pipeline['feature_columns']] = pipeline['scaler'].transform(df[pipeline['feature_columns']])\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Preprocess the new reading\n",
    "new_reading_processed = preprocess_data(new_reading_df, preprocessing_pipeline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8c6f65d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OxEnRa</th>\n",
       "      <th>BlFuPeIn</th>\n",
       "      <th>EnOxFl</th>\n",
       "      <th>CoBlFl</th>\n",
       "      <th>BlMo</th>\n",
       "      <th>BlFuBoGaVo</th>\n",
       "      <th>BlFuBoGaIn</th>\n",
       "      <th>ThCoTe</th>\n",
       "      <th>ToGaPr</th>\n",
       "      <th>EnOxPr</th>\n",
       "      <th>...</th>\n",
       "      <th>CoBlTe</th>\n",
       "      <th>HoBlTe</th>\n",
       "      <th>ToTe</th>\n",
       "      <th>BlHu</th>\n",
       "      <th>CoInSeVa</th>\n",
       "      <th>FoSI</th>\n",
       "      <th>HoBl</th>\n",
       "      <th>ToGasP</th>\n",
       "      <th>CoBF</th>\n",
       "      <th>SI_lag1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.186376</td>\n",
       "      <td>8.349047</td>\n",
       "      <td>-2.683261</td>\n",
       "      <td>109.636787</td>\n",
       "      <td>1.437173</td>\n",
       "      <td>0.655422</td>\n",
       "      <td>5.260941</td>\n",
       "      <td>2.878517</td>\n",
       "      <td>6.317686</td>\n",
       "      <td>2.180037</td>\n",
       "      <td>...</td>\n",
       "      <td>8.82853</td>\n",
       "      <td>0.475124</td>\n",
       "      <td>1.24104</td>\n",
       "      <td>4.778321</td>\n",
       "      <td>1.424068</td>\n",
       "      <td>5.483952</td>\n",
       "      <td>0.467971</td>\n",
       "      <td>2.653002</td>\n",
       "      <td>72.672068</td>\n",
       "      <td>4.00636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     OxEnRa  BlFuPeIn    EnOxFl      CoBlFl      BlMo  BlFuBoGaVo  BlFuBoGaIn  \\\n",
       "0  6.186376  8.349047 -2.683261  109.636787  1.437173    0.655422    5.260941   \n",
       "\n",
       "     ThCoTe    ToGaPr    EnOxPr  ...   CoBlTe    HoBlTe     ToTe      BlHu  \\\n",
       "0  2.878517  6.317686  2.180037  ...  8.82853  0.475124  1.24104  4.778321   \n",
       "\n",
       "   CoInSeVa      FoSI      HoBl    ToGasP       CoBF  SI_lag1  \n",
       "0  1.424068  5.483952  0.467971  2.653002  72.672068  4.00636  \n",
       "\n",
       "[1 rows x 24 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_reading_processed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa246ba",
   "metadata": {},
   "source": [
    "### Step 1: Set Up the Anomaly Detection System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a58dfb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing existing model\n",
    "model = joblib.load('Final_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4a9536e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SI Statistics from the model code\n",
    "training_stats = {\n",
    "    'si_mean': 0.46,\n",
    "    'si_std': 0.11,\n",
    "    'si_min': 0.18,\n",
    "    'si_max': 0.72\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9411a9",
   "metadata": {},
   "source": [
    "## Step 2: Create the Anomaly Detection Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "df8eecd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RealTimeAnomalyDetector:\n",
    "    def __init__(self, model, training_stats):\n",
    "        self.model = model\n",
    "        self.training_stats = training_stats\n",
    "        \n",
    "        # Initialize SHAP explainer (if using tree-based model)\n",
    "        self.explainer = shap.TreeExplainer(model)\n",
    "        \n",
    "        # Define anomaly thresholds\n",
    "        self.setup_thresholds()\n",
    "    \n",
    "    def setup_thresholds(self):\n",
    "        \"\"\"Define what constitutes an anomaly\"\"\"\n",
    "        mean = self.training_stats['si_mean']\n",
    "        std = self.training_stats['si_std']\n",
    "        \n",
    "        # Statistical thresholds (2-sigma rule)\n",
    "        self.upper_threshold = mean + 2 * std\n",
    "        self.lower_threshold = mean - 2 * std\n",
    "        \n",
    "        # Business thresholds (adjust based on domain knowledge)\n",
    "        self.critical_high = 0.85  # Furnace too hot\n",
    "        self.critical_low = 0.25   # Furnace too cold\n",
    "        \n",
    "        # Severe deviation threshold\n",
    "        self.severe_threshold = 0.15  # Absolute deviation\n",
    "    \n",
    "\n",
    "    def detect_anomaly(self, new_data_point):\n",
    "        \"\"\"\n",
    "        Main anomaly detection function\n",
    "        new_data_point: dict, pandas Series, or DataFrame with feature values\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Convert to DataFrame and ensure correct column order\n",
    "            if isinstance(new_data_point, dict):\n",
    "                input_data = pd.DataFrame([new_data_point])\n",
    "            elif isinstance(new_data_point, pd.Series):\n",
    "                input_data = pd.DataFrame([new_data_point])\n",
    "            else:\n",
    "                input_data = new_data_point\n",
    "\n",
    "            # Ensure columns match training features\n",
    "            if hasattr(self, 'feature_columns'):\n",
    "                # If you pass feature_columns to the class, use it\n",
    "                input_data = input_data[self.feature_columns]\n",
    "            elif hasattr(self.model, 'feature_names_in_'):\n",
    "                # For sklearn 1.0+\n",
    "                input_data = input_data[self.model.feature_names_in_]\n",
    "\n",
    "            # Make prediction\n",
    "            predicted_si = self.model.predict(input_data)[0]\n",
    "\n",
    "            # Classify anomaly type\n",
    "            anomaly_info = self._classify_anomaly(predicted_si)\n",
    "\n",
    "            if anomaly_info['is_anomaly']:\n",
    "                # Generate explanations and recommendations\n",
    "                explanations = self._explain_prediction(input_data.iloc[0])\n",
    "                recommendations = self._generate_recommendations(explanations, predicted_si)\n",
    "\n",
    "                return {\n",
    "                    'timestamp': datetime.now().isoformat(),\n",
    "                    'predicted_si': round(predicted_si, 4),\n",
    "                    'anomaly_detected': True,\n",
    "                    'anomaly_type': anomaly_info['type'],\n",
    "                    'severity': anomaly_info['severity'],\n",
    "                    'explanations': explanations,\n",
    "                    'recommendations': recommendations,\n",
    "                    'alert_message': self._create_alert_message(predicted_si, anomaly_info)\n",
    "                }\n",
    "            else:\n",
    "                return {\n",
    "                    'timestamp': datetime.now().isoformat(),\n",
    "                    'predicted_si': round(predicted_si, 4),\n",
    "                    'anomaly_detected': False,\n",
    "                    'status': 'Normal operation',\n",
    "                    'alert_message': f\"SI prediction: {predicted_si:.3f}% - Within normal range\"\n",
    "                }\n",
    "\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                'error': f\"Prediction failed: {str(e)}\",\n",
    "                'timestamp': datetime.now().isoformat()\n",
    "            }\n",
    "    \n",
    "    def _classify_anomaly(self, predicted_si):\n",
    "        \"\"\"Classify the type and severity of anomaly\"\"\"\n",
    "        \n",
    "        anomaly_info = {'is_anomaly': False, 'type': None, 'severity': 'normal'}\n",
    "        \n",
    "        # Check critical thresholds first\n",
    "        if predicted_si >= self.critical_high:\n",
    "            anomaly_info = {\n",
    "                'is_anomaly': True,\n",
    "                'type': 'critical_high_si',\n",
    "                'severity': 'critical'\n",
    "            }\n",
    "        elif predicted_si <= self.critical_low:\n",
    "            anomaly_info = {\n",
    "                'is_anomaly': True,\n",
    "                'type': 'critical_low_si',\n",
    "                'severity': 'critical'\n",
    "            }\n",
    "        # Check statistical thresholds\n",
    "        elif predicted_si > self.upper_threshold:\n",
    "            anomaly_info = {\n",
    "                'is_anomaly': True,\n",
    "                'type': 'high_si',\n",
    "                'severity': 'moderate'\n",
    "            }\n",
    "        elif predicted_si < self.lower_threshold:\n",
    "            anomaly_info = {\n",
    "                'is_anomaly': True,\n",
    "                'type': 'low_si',\n",
    "                'severity': 'moderate'\n",
    "            }\n",
    "        \n",
    "        return anomaly_info\n",
    "    \n",
    "    def _explain_prediction(self, data_point):\n",
    "        \"\"\"Use SHAP to explain why the prediction is anomalous\"\"\"\n",
    "        \n",
    "        # Get SHAP values\n",
    "        shap_values = self.explainer.shap_values([data_point])\n",
    "        feature_names = data_point.index.tolist()\n",
    "        \n",
    "        # Create explanation dictionary\n",
    "        explanations = {}\n",
    "        for i, feature in enumerate(feature_names):\n",
    "            explanations[feature] = {\n",
    "                'shap_value': round(shap_values[0][i], 4),\n",
    "                'feature_value': round(data_point.iloc[i], 4),\n",
    "                'contribution': 'positive' if shap_values[0][i] > 0 else 'negative'\n",
    "            }\n",
    "        \n",
    "        # Get top 5 most influential features\n",
    "        top_features = sorted(explanations.items(), \n",
    "                            key=lambda x: abs(x[1]['shap_value']), \n",
    "                            reverse=True)[:5]\n",
    "        \n",
    "        return {\n",
    "            'all_features': explanations,\n",
    "            'top_contributors': dict(top_features)\n",
    "        }\n",
    "    \n",
    "    def _generate_recommendations(self, explanations, predicted_si):\n",
    "        \"\"\"Generate corrective action recommendations\"\"\"\n",
    "        \n",
    "        recommendations = []\n",
    "        top_contributors = explanations['top_contributors']\n",
    "        \n",
    "        for feature, info in top_contributors.items():\n",
    "            shap_val = info['shap_value']\n",
    "            \n",
    "            # Only recommend for significant contributors\n",
    "            if abs(shap_val) > 0.02:\n",
    "                \n",
    "                if 'BlTe' in feature or 'BlastTemp' in feature:\n",
    "                    if shap_val > 0 and predicted_si > 0.6:\n",
    "                        recommendations.append({\n",
    "                            'action': 'Reduce blast temperature',\n",
    "                            'reason': f'High temperature contributing +{shap_val:.3f} to elevated SI',\n",
    "                            'priority': 'high' if abs(shap_val) > 0.05 else 'medium'\n",
    "                        })\n",
    "                    elif shap_val < 0 and predicted_si < 0.4:\n",
    "                        recommendations.append({\n",
    "                            'action': 'Increase blast temperature',\n",
    "                            'reason': f'Low temperature contributing {shap_val:.3f} to reduced SI',\n",
    "                            'priority': 'high' if abs(shap_val) > 0.05 else 'medium'\n",
    "                        })\n",
    "                \n",
    "                elif 'OxEnRa' in feature or 'Oxygen' in feature:\n",
    "                    if shap_val > 0 and predicted_si > 0.6:\n",
    "                        recommendations.append({\n",
    "                            'action': 'Reduce oxygen enrichment',\n",
    "                            'reason': f'High oxygen contributing +{shap_val:.3f} to elevated SI',\n",
    "                            'priority': 'medium'\n",
    "                        })\n",
    "                \n",
    "                elif 'ToGaPr' in feature or 'Pressure' in feature:\n",
    "                    if shap_val < 0 and predicted_si < 0.4:\n",
    "                        recommendations.append({\n",
    "                            'action': 'Increase top gas pressure',\n",
    "                            'reason': f'Low pressure contributing {shap_val:.3f} to reduced SI',\n",
    "                            'priority': 'medium'\n",
    "                        })\n",
    "        \n",
    "        # If no specific recommendations, provide general ones\n",
    "        if not recommendations:\n",
    "            if predicted_si > 0.7:\n",
    "                recommendations.append({\n",
    "                    'action': 'Review overall thermal conditions',\n",
    "                    'reason': 'SI elevated but no clear single cause identified',\n",
    "                    'priority': 'low'\n",
    "                })\n",
    "            elif predicted_si < 0.3:\n",
    "                recommendations.append({\n",
    "                    'action': 'Check furnace thermal state',\n",
    "                    'reason': 'SI low but no clear single cause identified',\n",
    "                    'priority': 'low'\n",
    "                })\n",
    "        \n",
    "        return recommendations\n",
    "    \n",
    "    def _create_alert_message(self, predicted_si, anomaly_info):\n",
    "        \"\"\"Create human-readable alert message\"\"\"\n",
    "        \n",
    "        severity = anomaly_info['severity']\n",
    "        anomaly_type = anomaly_info['type']\n",
    "        \n",
    "        if severity == 'critical':\n",
    "            if 'high' in anomaly_type:\n",
    "                return f\"🚨 CRITICAL ALERT: SI predicted at {predicted_si:.3f}% - Furnace overheating risk!\"\n",
    "            else:\n",
    "                return f\"🚨 CRITICAL ALERT: SI predicted at {predicted_si:.3f}% - Furnace too cold!\"\n",
    "        elif severity == 'moderate':\n",
    "            if 'high' in anomaly_type:\n",
    "                return f\"⚠️ WARNING: SI predicted at {predicted_si:.3f}% - Above normal range\"\n",
    "            else:\n",
    "                return f\"⚠️ WARNING: SI predicted at {predicted_si:.3f}% - Below normal range\"\n",
    "        \n",
    "        return f\"ℹ️ INFO: SI predicted at {predicted_si:.3f}% - Normal operation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b2c7b768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the anomaly detector\n",
    "detector = RealTimeAnomalyDetector(model, training_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3a9c092c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alert: SI prediction: 0.522% - Within normal range\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ABC1\\Documents\\GitHub\\Ml-problem-framework\\Tvarit - Lead DS assignment\\Solution file\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2742: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Run anomaly detection\n",
    "\n",
    "result = detector.detect_anomaly(new_reading_processed)\n",
    "print(f\"Alert: {result['alert_message']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "12b62c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "if result['anomaly_detected']:\n",
    "    print(f\"Severity: {result['severity']}\")\n",
    "    print(\"Recommendations:\")\n",
    "    for rec in result['recommendations']:\n",
    "        print(f\"- {rec['action']}: {rec['reason']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97737f8",
   "metadata": {},
   "source": [
    "Step 4: Integration for Real-Time Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e31a0e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_real_time_monitoring(detector, test_data, n_samples=10):\n",
    "    \"\"\"Simulate real-time monitoring with your test data\"\"\"\n",
    "    \n",
    "    print(\"=== REAL-TIME ANOMALY DETECTION SIMULATION ===\\n\")\n",
    "    \n",
    "    anomaly_count = 0\n",
    "    \n",
    "    for i in range(min(n_samples, len(test_data))):\n",
    "        sample = test_data.iloc[i]\n",
    "        result = detector.detect_anomaly(sample)\n",
    "        \n",
    "        print(f\"Time {i+1}: {result['alert_message']}\")\n",
    "        \n",
    "        if result['anomaly_detected']:\n",
    "            anomaly_count += 1\n",
    "            print(f\"  Severity: {result['severity']}\")\n",
    "            if result.get('recommendations'):\n",
    "                print(\"  Top Recommendation:\", result['recommendations'][0]['action'])\n",
    "            print()\n",
    "    \n",
    "    print(f\"Summary: {anomaly_count}/{n_samples} samples flagged as anomalies\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9a508a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run simulation with your test data\n",
    "# simulate_real_time_monitoring(detector, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32728e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
